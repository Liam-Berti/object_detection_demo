{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c63ffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T17:13:31.852809Z",
     "start_time": "2022-03-17T17:13:31.408598Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def vgg_block(n_convs: int, in_ch: int, out_ch: int) -> nn.Sequential:\n",
    "    layers = list()\n",
    "    for _ in range(n_convs):\n",
    "        layers.append(nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_ch = out_ch\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def vgg(\n",
    "    conv_arch: Tuple[Tuple[int, int], ...],\n",
    "    in_channels: int = 1,\n",
    "    in_dims: Tuple[int, int] = (244, 244),\n",
    "    n_classes: int = 10,\n",
    ") -> nn.Sequential:\n",
    "    conv_blks = []\n",
    "    # The convolutional part\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "        in_dims = (in_dims[0] // 2, in_dims[1] // 2)\n",
    "\n",
    "    return nn.Sequential(\n",
    "        *conv_blks,\n",
    "        nn.Flatten(),\n",
    "        # The fully-connected part\n",
    "        nn.Linear(out_channels * in_dims[0] * in_dims[1], 4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(4096, n_classes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d0dd47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T17:13:32.368624Z",
     "start_time": "2022-03-17T17:13:31.854341Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.data import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_root = \"../data/raw/imagenette2-320/\"\n",
    "\n",
    "dims = (64, 64)\n",
    "trans = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(dims),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_set = datasets.Imagenette(\n",
    "    data_root + \"noisy_imagenette.csv\", data_root, train=True, transform=trans\n",
    ")\n",
    "validation_set = datasets.Imagenette(\n",
    "    data_root + \"noisy_imagenette.csv\", data_root, train=False, transform=trans\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(validation_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "net = vgg(conv_arch, in_channels=3, in_dims=dims, n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e583f8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T17:17:48.472336Z",
     "start_time": "2022-03-17T17:17:48.463580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0064)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "output = Variable(torch.FloatTensor([0,0,1,1])).view(1, -1)\n",
    "target = Variable(torch.LongTensor([3]))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dc62cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T07:00:43.078502Z",
     "start_time": "2022-03-17T07:00:43.065866Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_net(net, trainloader, num_epochs, lr, device):\n",
    "    net.to(device)\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    \n",
    "    import torch.optim as optim\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bb23eb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T07:09:38.592174Z",
     "start_time": "2022-03-17T07:00:47.547039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.298\n",
      "[2,  2000] loss: 2.265\n",
      "[3,  2000] loss: 2.083\n",
      "[4,  2000] loss: 1.910\n",
      "[5,  2000] loss: 1.762\n",
      "[6,  2000] loss: 1.628\n",
      "[7,  2000] loss: 1.535\n",
      "[8,  2000] loss: 1.424\n",
      "[9,  2000] loss: 1.342\n",
      "[10,  2000] loss: 1.243\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 10\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "train_net(net, train_loader, num_epochs, lr, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "427cb45e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T07:17:57.242442Z",
     "start_time": "2022-03-17T07:17:56.831825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2], device='cuda:0')\n",
      "tensor([2, 4, 6, 2])\n",
      "tensor([0, 3, 2, 5], device='cuda:0')\n",
      "tensor([8, 0, 8, 5])\n",
      "tensor([8, 2, 2, 6], device='cuda:0')\n",
      "tensor([7, 4, 9, 6])\n",
      "tensor([2, 4, 8, 5], device='cuda:0')\n",
      "tensor([2, 4, 3, 4])\n",
      "tensor([5, 2, 2, 4], device='cuda:0')\n",
      "tensor([5, 2, 1, 4])\n",
      "tensor([0, 5, 0, 2], device='cuda:0')\n",
      "tensor([0, 5, 0, 9])\n",
      "tensor([3, 7, 2, 1], device='cuda:0')\n",
      "tensor([3, 4, 2, 1])\n",
      "tensor([3, 6, 9, 1], device='cuda:0')\n",
      "tensor([3, 0, 4, 1])\n",
      "tensor([2, 2, 1, 6], device='cuda:0')\n",
      "tensor([8, 3, 1, 6])\n",
      "tensor([4, 1, 5, 2], device='cuda:0')\n",
      "tensor([5, 4, 6, 2])\n",
      "tensor([4, 0, 2, 0], device='cuda:0')\n",
      "tensor([4, 0, 8, 8])\n",
      "tensor([6, 3, 2, 3], device='cuda:0')\n",
      "tensor([9, 9, 2, 0])\n",
      "tensor([9, 2, 6, 5], device='cuda:0')\n",
      "tensor([9, 2, 6, 5])\n",
      "tensor([3, 5, 6, 4], device='cuda:0')\n",
      "tensor([7, 8, 6, 4])\n",
      "tensor([1, 2, 1, 2], device='cuda:0')\n",
      "tensor([1, 8, 0, 2])\n",
      "tensor([2, 4, 6, 1], device='cuda:0')\n",
      "tensor([8, 4, 6, 1])\n",
      "tensor([5, 2, 5, 5], device='cuda:0')\n",
      "tensor([8, 7, 5, 7])\n",
      "tensor([3, 4, 0, 6], device='cuda:0')\n",
      "tensor([3, 4, 7, 4])\n",
      "tensor([8, 2, 2, 6], device='cuda:0')\n",
      "tensor([5, 2, 7, 6])\n",
      "tensor([3, 6, 4, 5], device='cuda:0')\n",
      "tensor([3, 6, 4, 5])\n",
      "tensor([5, 2, 6, 5], device='cuda:0')\n",
      "tensor([8, 2, 6, 5])\n",
      "tensor([7, 3, 9, 4], device='cuda:0')\n",
      "tensor([6, 3, 9, 7])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "\n",
    "i = 0\n",
    "for x, y in valid_loader:\n",
    "    X = x.to(device)\n",
    "    logits = net(X)\n",
    "    pred_probab = nn.Softmax(dim=1)(logits)\n",
    "    y_pred = pred_probab.argmax(1)\n",
    "    print(y_pred)\n",
    "    print(y)\n",
    "    if i > 20:\n",
    "        break\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80492ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T07:18:48.310116Z",
     "start_time": "2022-03-17T07:18:48.096066Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d328a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
